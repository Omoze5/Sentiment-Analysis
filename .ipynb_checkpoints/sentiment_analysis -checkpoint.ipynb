{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9de207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3555a744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     label\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...  positive\n",
      "1  Homelessness (or Houselessness as George Carli...  positive\n",
      "2  Brilliant over-acting by Lesley Ann Warren. Be...  positive\n",
      "3  This is easily the most underrated film inn th...  positive\n",
      "4  This is not the typical Mel Brooks film. It wa...  positive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# importing the train dataset\n",
    "\n",
    "# Path to the train dataset folder\n",
    "dataset_path = \"C:\\\\Users\\\\HP\\\\OneDrive\\\\NLP PROJECT\\\\SENTIMENT_ANALYSIS\\\\train\"\n",
    "\n",
    "# Initialize lists to store data\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "# Read positive text files\n",
    "positive_path = os.path.join(dataset_path, 'pos')\n",
    "for filename in os.listdir(positive_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(positive_path, filename), 'r', encoding='utf-8') as file:\n",
    "            texts.append(file.read())\n",
    "            labels.append('positive')\n",
    "\n",
    "# Read negative text files\n",
    "negative_path = os.path.join(dataset_path, 'neg')\n",
    "for filename in os.listdir(negative_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(negative_path, filename), 'r', encoding='utf-8') as file:\n",
    "            texts.append(file.read())\n",
    "            labels.append('negative')\n",
    "\n",
    "# Create a DataFrame\n",
    "train_df = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "# Display the first few rows\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a845a3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outputs the shape of the train dataset\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43cdfbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "positive    12500\n",
       "negative    12500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of the train label\n",
    "\n",
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2d4b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0610e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the train text by tokenizing, removing stop words and also reducing the txt to their base word\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(txt):\n",
    "    doc = nlp(txt)\n",
    "    filtered_token = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            filtered_token.append(token.lemma_.lower())\n",
    "    return \" \".join(filtered_token)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b4711c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"text_preprocesed\"] = train_df[\"text\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "632979de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing the text and the preprocessed and noting the difference\n",
    "train_df[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c0ae90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high cartoon comedy run time program school life teachers 35 year teaching profession lead believe bromwell high satire close reality teachers scramble survive financially insightful student right pathetic teacher pomp pettiness situation remind school know student see episode student repeatedly try burn school immediately recall high classic line inspector sack teacher student welcome bromwell high expect adult age think bromwell high far fetch pity'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text_preprocesed\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e43b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing the training label also\n",
    "\n",
    "train_df[\"label_preprocess\"] = train_df[\"label\"].map({\"positive\": 0, \"negative\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d1d52d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_preprocesed</th>\n",
       "      <th>label_preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>bromwell high cartoon comedy run time program ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>positive</td>\n",
       "      <td>homelessness houselessness george carlin state...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>positive</td>\n",
       "      <td>brilliant act lesley ann warren well dramatic ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>easily underrated film inn brooks cannon sure ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>positive</td>\n",
       "      <td>typical mel brooks film slapstick movie actual...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...  positive   \n",
       "1  Homelessness (or Houselessness as George Carli...  positive   \n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...  positive   \n",
       "3  This is easily the most underrated film inn th...  positive   \n",
       "4  This is not the typical Mel Brooks film. It wa...  positive   \n",
       "\n",
       "                                    text_preprocesed  label_preprocess  \n",
       "0  bromwell high cartoon comedy run time program ...                 0  \n",
       "1  homelessness houselessness george carlin state...                 0  \n",
       "2  brilliant act lesley ann warren well dramatic ...                 0  \n",
       "3  easily underrated film inn brooks cannon sure ...                 0  \n",
       "4  typical mel brooks film slapstick movie actual...                 0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28b283b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     label\n",
      "0  I went and saw this movie last night after bei...  positive\n",
      "1  Actor turned director Bill Paxton follows up h...  positive\n",
      "2  As a recreational golfer with some knowledge o...  positive\n",
      "3  I saw this film in a sneak preview, and it is ...  positive\n",
      "4  Bill Paxton has taken the true story of the 19...  positive\n"
     ]
    }
   ],
   "source": [
    "# importing the test dataset\n",
    "import os\n",
    "\n",
    "# Path to the dataset folder\n",
    "dataset_path = \"C:\\\\Users\\\\HP\\\\OneDrive\\\\NLP PROJECT\\\\SENTIMENT_ANALYSIS\\\\test\"\n",
    "\n",
    "# Initialize lists to store data\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "# Read positive text files\n",
    "positive_path = os.path.join(dataset_path, 'pos')\n",
    "for filename in os.listdir(positive_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(positive_path, filename), 'r', encoding='utf-8') as file:\n",
    "            texts.append(file.read())\n",
    "            labels.append('positive')\n",
    "\n",
    "# Read negative text files\n",
    "negative_path = os.path.join(dataset_path, 'neg')\n",
    "for filename in os.listdir(negative_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(negative_path, filename), 'r', encoding='utf-8') as file:\n",
    "            texts.append(file.read())\n",
    "            labels.append('negative')\n",
    "\n",
    "# Create a DataFrame\n",
    "test_df = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "# Display the first few rows of the test data\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3652a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"text_preprocesed\"] = test_df[\"text\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2827fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"label_preprocess\"] = test_df[\"label\"].map({\"positive\": 0, \"negative\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "318e1164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_preprocesed</th>\n",
       "      <th>label_preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>positive</td>\n",
       "      <td>go see movie night coax friend admit reluctant...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>positive</td>\n",
       "      <td>actor turn director bill paxton follow promisi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>recreational golfer knowledge sport history pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>see film sneak preview delightful cinematograp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>positive</td>\n",
       "      <td>bill paxton take true story 1913 golf open fil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0  I went and saw this movie last night after bei...  positive   \n",
       "1  Actor turned director Bill Paxton follows up h...  positive   \n",
       "2  As a recreational golfer with some knowledge o...  positive   \n",
       "3  I saw this film in a sneak preview, and it is ...  positive   \n",
       "4  Bill Paxton has taken the true story of the 19...  positive   \n",
       "\n",
       "                                    text_preprocesed  label_preprocess  \n",
       "0  go see movie night coax friend admit reluctant...                 0  \n",
       "1  actor turn director bill paxton follow promisi...                 0  \n",
       "2  recreational golfer knowledge sport history pl...                 0  \n",
       "3  see film sneak preview delightful cinematograp...                 0  \n",
       "4  bill paxton take true story 1913 golf open fil...                 0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa8c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62fb64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48c6241a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;MultinomialNB&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;MultinomialNB&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Vectorizer', TfidfVectorizer()),\n",
       "                ('MultinomialNB', MultinomialNB())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizing the text by converting them to vectors using TF-IDF\n",
    "# Training the model using naive bayes\n",
    "# streamling both processess using pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "\n",
    "X_train = train_df[\"text_preprocesed\"]\n",
    "y_train = train_df[\"label_preprocess\"]\n",
    "\n",
    "X_test = test_df[\"text_preprocesed\"]\n",
    "y_test = test_df[\"label_preprocess\"]\n",
    "\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"Vectorizer\", TfidfVectorizer()),  # Vectorize preprocessed text\n",
    "    (\"MultinomialNB\", MultinomialNB())  # Train Naive Bayes classifier\n",
    "])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125529ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c48b8b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8238"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed the unseen data into the model and check for the accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72c1c660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81     12500\n",
      "           1       0.79      0.87      0.83     12500\n",
      "\n",
      "    accuracy                           0.82     25000\n",
      "   macro avg       0.83      0.82      0.82     25000\n",
      "weighted avg       0.83      0.82      0.82     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91809d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;MultinomialNB&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;MultinomialNB&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Vectorizer', TfidfVectorizer()),\n",
       "                ('MultinomialNB', LogisticRegression())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using another algorithm to compare \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "LR_model = Pipeline([\n",
    "    (\"Vectorizer\", TfidfVectorizer()),\n",
    "    (\"MultinomialNB\", LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "LR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31cb69a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87504"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed the unseen data into the logistics regression model and check for the accuracy\n",
    "y_pred = LR_model.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d094c0a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88     12500\n",
      "           1       0.88      0.87      0.87     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c93cf",
   "metadata": {},
   "source": [
    "The logistics regression performed better than the naive bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1c9a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the Logistic regression model \n",
    "import pickle\n",
    "\n",
    "pickle.dump(LR_model, open('my_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9642c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
